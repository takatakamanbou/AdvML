{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/AdvML/blob/2024/AdvML2024_ex07notebookA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzDNLmVS3po"
      },
      "source": [
        "# AdvML ex07notebookA\n",
        "\n",
        "<img width=72 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/AdvML/AdvML-logo.png\"> [この授業のウェブページ](https://www-tlab.math.ryukoku.ac.jp/wiki/?AdvML)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ0oDxG3iygx"
      },
      "source": [
        "----\n",
        "## 準備\n",
        "----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "「例1」のセクションの実行のために必要な import 文等は，そちらのせくよんの中の「準備」にまとめてあります．"
      ],
      "metadata": {
        "id": "kcXXfU2qmbtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 準備あれこれ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set()\n",
        "\n",
        "# OpenCV のあれこれ\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "RjLTO96x2EvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 畳み込みニューラルネットワーク\n",
        "---\n"
      ],
      "metadata": {
        "id": "qrKE45oj_dUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**畳み込み** (convolution) という演算を行う層（**畳み込み層**）を含むニューラルネットのこと．\n",
        "Convolutional Neural Network を略して CNN と呼ばれる．"
      ],
      "metadata": {
        "id": "-dEs4DcxZjXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 画像のような情報を階層型ニューラルネットで扱おう"
      ],
      "metadata": {
        "id": "oYIM_i2xXPug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 問題点と改善策"
      ],
      "metadata": {
        "id": "Jq5ygE3cXwoO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1次元の畳み込み"
      ],
      "metadata": {
        "id": "NAAqvClrX1sD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$T$ 個の数値 $x_1, x_2, \\ldots, x_T$ がこの順に一列に並んだデータを考える．\n",
        "このとき，このデータに対する1次元畳み込みを次式で定義する（注1）．\n",
        "\n",
        "$$\n",
        "y_t = \\sum_{k=0}^{K-1} w_{k} x_{t+k}\n",
        "$$\n",
        "\n",
        "$y_t$ の値は，$K$ 個の値 $x_t, x_{t+1}, \\ldots, x_{t+K-1}$  に $w_{0}, w_{1}, \\ldots, w_{K-1}$ のそれぞれを掛けてそれらの和をとったものである（注2）．\n",
        "$w_k (k = 0, 1, \\ldots, K-1)$ という $K$ 個の値の組を，「カーネル」または「フィルタ」という．\n",
        "カーネルの値を変えると，$x_t$ が同じ値でも得られる $y_t$ の値は変化する．"
      ],
      "metadata": {
        "id": "DmB2ys7Kn_Kt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "※ 注1 ここでは，ニューラルネットの分野で一般的な「畳み込み」の定義を採用している．\n",
        "この定義は，「畳み込み」という語が元々用いられてきた信号処理の分野における定義とは少し異なっているので，注意が必要である．この定義は，信号処理の世界では「相互相関」と呼ばれるものに近い．\n",
        "\n",
        "※ 注2 この式の通りだと，$t = T - K + 1, \\ldots, T$ の場合に $x_t$ の添え字が $T$ より大きくなる場合が生じるため，$y_t$ を計算できなくなる．\n",
        "畳み込みニューラルネットにおいては，範囲からはみ出した部分に $0$ が入っていると仮定して計算する，等の処理（パディングと呼ばれる）がよく行われる．\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ajCoINfzp9wv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2次元の畳み込み\n",
        "\n",
        "$W \\times H$ 個の数値 $v_{x, y}$ ($x = 1, 2, \\ldots, W, y = 1, 2, \\ldots, H$) が縦横にならんだデータを考える（例: グレイスケール画像）．\n",
        "このデータに対する2次元畳み込みを次式で定義する（注3）．\n",
        "\n",
        "$$\n",
        "y_{x, y} = \\sum_{i = 0}^{K-1}\\sum_{j=0}^{K-1} w_{i, j} v_{x+i, y+j}\n",
        "$$\n",
        "\n",
        "1次元の場合と同様に，$w_{i, j}$ ($i = 0, 1, \\ldots, K-1, j = 0, 1, \\ldots, K-1$) という $K^2$ 個の値の組を「カーネル」または「フィルタ」という"
      ],
      "metadata": {
        "id": "lGIxZDxbzMSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "※ 注3 ここではカーネルの縦横のサイズが同じと仮定している．これは説明の簡単のためであり，実際には縦横でサイズが異なっていてもよい．\n",
        "また，画像の場合，$y_{x,y}$ の値は，カーネルの中心が $(x, y)$ に来るようにして計算する方が都合がよいので，画像処理や畳み込みニューラルネットではそのような実装となっていることが多い．"
      ],
      "metadata": {
        "id": "i3cKeHNQ1KZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3次元畳み込み\n",
        "\n",
        "カラー画像は，縦横に加えて色の軸をもつ3次元配列と考えることができるので，\n",
        "画像を扱う畳み込みニューラルネットでは 3次元の畳み込みを用いるのが一般的である．\n",
        "2次元の場合の自然な拡張として容易に理解できるので，式の定義や説明は省略する．"
      ],
      "metadata": {
        "id": "UIYpu3fE1Mea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### グレイスケール画像の畳み込み（フィルタリング）"
      ],
      "metadata": {
        "id": "_ByWmhq_YK3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "畳み込みがどのような計算であるかを直感的に理解するために，グレイスケール画像に2次元畳み込みを適用する実験をやってみよう．"
      ],
      "metadata": {
        "id": "rQC0z5XA3XoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 実験用画像を入手して表示する\n",
        "\n",
        "! wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/hogelogo.png\n",
        "! wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/uni3.png\n",
        "\n",
        "imgHOGE = cv2.imread('hogelogo.png', cv2.IMREAD_GRAYSCALE)\n",
        "print(imgHOGE.shape)\n",
        "cv2_imshow(imgHOGE)\n",
        "\n",
        "print()\n",
        "\n",
        "imgUni3G = cv2.imread('uni3.png', cv2.IMREAD_GRAYSCALE)\n",
        "print(imgUni3G.shape)\n",
        "\n",
        "cv2_imshow(imgUni3G)"
      ],
      "metadata": {
        "id": "EvOriy4Z3j63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "まずは，「平滑化」呼ばれる処理の例． 画像がぼける．\n",
        "`kx`, `ky`でカーネルの幅と高さを指定しているので，変えてみよう．"
      ],
      "metadata": {
        "id": "LYI6MUQ63sUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 平滑化フィルタ\n",
        "kx, ky = 3, 3\n",
        "kernel = np.ones((ky, kx)) / (kx*ky)\n",
        "print(kernel)\n",
        "\n",
        "# フィルタリング\n",
        "img1 = cv2.filter2D(imgHOGE, cv2.CV_32F, kernel)\n",
        "img2 = cv2.filter2D(imgUni3G, cv2.CV_32F, kernel)\n",
        "\n",
        "# 表示\n",
        "cv2_imshow(img1)\n",
        "print()\n",
        "cv2_imshow(img2)"
      ],
      "metadata": {
        "id": "8MYGEgn137sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次は，Sobel フィルタと呼ばれるフィルタの例．この例の Sobel フィルタは，画像の水平方向のエッジ（明るさが急激に変化する箇所）に反応する．\n",
        "この場合，出力が正負の値をとり，元の画素値の範囲におさまらなくなるので，0 が画素値128の灰色，正の所が白，負の所が黒になるように値を変換している．"
      ],
      "metadata": {
        "id": "KOMXQewg366O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 水平方向のエッジを検出する Sobel フィルタ\n",
        "kernel = np.array( [[-1, 0, 1],\n",
        "                   [-2, 0, 2],\n",
        "                   [-1, 0, 1]] )\n",
        "print(kernel)\n",
        "\n",
        "# フィルタリング\n",
        "img1 = cv2.filter2D(imgHOGE, cv2.CV_32F, kernel)\n",
        "img2 = cv2.filter2D(imgUni3G, cv2.CV_32F, kernel)\n",
        "\n",
        "# フィルタリング後の値が [0, 255] の範囲におさまるようにする\n",
        "img1 = img1 / np.max(np.abs(img1)) * 127 + 128\n",
        "img2 = img2 / np.max(np.abs(img2)) * 127 + 128\n",
        "\n",
        "# 表示\n",
        "cv2_imshow(img1)\n",
        "print()\n",
        "cv2_imshow(img2)"
      ],
      "metadata": {
        "id": "b6hiChzG4Qej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sobel フィルタの向きを変えると，垂直方向のエッジも抽出できる．"
      ],
      "metadata": {
        "id": "pwOZb3vz4PoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 垂直方向のエッジを検出する Sobel フィルタ\n",
        "kernel = np.array( [[-1, -2, -1],\n",
        "                    [ 0,  0,  0],\n",
        "                    [ 1,  2,  1]] )\n",
        "print(kernel)\n",
        "\n",
        "# フィルタリング\n",
        "img1 = cv2.filter2D(imgHOGE, cv2.CV_32F, kernel)\n",
        "img2 = cv2.filter2D(imgUni3G, cv2.CV_32F, kernel)\n",
        "\n",
        "# フィルタリング後の値が [0, 255] の範囲におさまるようにする\n",
        "img1 = img1 / np.max(np.abs(img1)) * 127 + 128\n",
        "img2 = img2 / np.max(np.abs(img2)) * 127 + 128\n",
        "\n",
        "# 表示\n",
        "cv2_imshow(img1)\n",
        "print()\n",
        "cv2_imshow(img2)"
      ],
      "metadata": {
        "id": "42zw8CJY5DUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "### 畳み込みニューラルネットの構造"
      ],
      "metadata": {
        "id": "guMc68TbYRTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "典型的な畳み込みニューラルネット（特に画像識別に適用されるもの）は，入力側から順に， **畳み込み層** と **プーリング層** (pooling layer) を何層か繰り返した後に **全結合層** (fully connected layer) を何層か繰り返す，という構造をしている．"
      ],
      "metadata": {
        "id": "67KYSxwKYkIQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 畳み込み層"
      ],
      "metadata": {
        "id": "w1-B-aQaZPPN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### プーリング層"
      ],
      "metadata": {
        "id": "msxcW1YyZRgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 全結合層"
      ],
      "metadata": {
        "id": "F4Y0sF-lZUkm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 例1: 手書き数字を識別する CNN"
      ],
      "metadata": {
        "id": "WT10lMpHZaPR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNISTデータセット（の一部）を用いた実験をやってみよう．レポート課題でも同じデータセットを用いていた．"
      ],
      "metadata": {
        "id": "m6g9n6WWaSjI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 準備"
      ],
      "metadata": {
        "id": "P1mSbrk_aplT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 準備あれこれ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set()\n",
        "\n",
        "# scikie-learn のあれこれ\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# PyTorch 関係のほげ\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchsummary"
      ],
      "metadata": {
        "id": "S5ywbULWmWKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST データセットの入手\n",
        "Xraw, yraw = fetch_openml('mnist_784', version=1, parser='auto', return_X_y=True, as_frame=False)\n",
        "Xall = Xraw[:20000] / 255.0     # 画素値が [0, 255] の整数値なので [0, 1] の浮動小数点数値に変換\n",
        "yall = yraw[:20000].astype(int) # クラスラベル．0 から 9 の整数値\n",
        "\n",
        "# 学習データとテストデータの分割\n",
        "XL, XT, yL, yT = train_test_split(Xall, yall, test_size=4000, random_state=4649, stratify=yall)\n",
        "print(XL.shape, yL.shape)\n",
        "print(XT.shape, yT.shape)"
      ],
      "metadata": {
        "id": "fbXMC1CPXYl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PyTorch"
      ],
      "metadata": {
        "id": "7KWzZTEzbC1c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここでは，Python の深層学習フレームワーク（Python で深層学習のプログラムを作成するためのソフトウェアライブラリ）の代表格である PyTorch を用いる．\n",
        "\n",
        "https://pytorch.org/\n",
        "\n",
        "PyTorch のプログラムは，通常通り CPU 上で実行するだけでなく，GPU 上で実行することもできる．\n",
        "GPU は画像処理等の計算に特化している分，CPU よりも並列計算の性能が優れている．\n",
        "ニューラルネットの計算は並列処理に向いているため， GPU を利用することで，より高速な計算が可能となる．"
      ],
      "metadata": {
        "id": "dKzwDzE_bFfP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab の場合，デフォルトでは PyTorch のプログラムも CPU 上で実行されるが，次のように設定することで，GPU を利用できるようになる．\n",
        "\n",
        "1. Colab のメニューから「ランタイム」>「ランタイムのタイプを変更」>「CPU」に代えて「T4 GPU」を選択して「保存」\n",
        "1. ランタイムが初期化されるので，全てのコードセルを最初から実行し直す必要ある．\n",
        "このセクションの実験の場合，「例1」のセクションの「準備」のコードセルを実行し直すのでok\n",
        "1. 次のコードセルを実行して，`cuda` と表示されれば， PyTorch で GPU が使える状態になっている．`cpu` と表示される場合は，GPU が使えるようになっておらず，PyTorch のプログラムは CPU で実行される．\n"
      ],
      "metadata": {
        "id": "4uxksuRYdI7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "USuhbWT9avMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 実験の準備"
      ],
      "metadata": {
        "id": "4pS8ix1ufuco"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "実験で用いるプログラムの準備"
      ],
      "metadata": {
        "id": "OmAbRN5Cf8xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを扱うためのクラス\n",
        "#\n",
        "class MMDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataX, dataY):\n",
        "        self.X = dataX.reshape((-1, 1, 28, 28))\n",
        "        self.Y = dataY\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.Y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = torch.tensor(self.X[idx], dtype=torch.float32)\n",
        "        y = torch.tensor(self.Y[idx], dtype=torch.int64)\n",
        "        return X, y"
      ],
      "metadata": {
        "id": "iQslC85Sfnpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 階層型ニューラルネットの構造と入出力を定義するクラス\n",
        "#\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, numNeurons):\n",
        "        super(MLP, self).__init__()\n",
        "        numLayers = len(numNeurons)\n",
        "        assert numLayers >= 2\n",
        "        L = [nn.Flatten()] # [1, 28, 28] => 784\n",
        "        # 中間層\n",
        "        for i in range(numLayers-2):\n",
        "            L.append(nn.Linear(numNeurons[i], numNeurons[i+1]))\n",
        "            L.append(nn.ReLU())\n",
        "        # 出力層\n",
        "        L.append(nn.Linear(numNeurons[-2], numNeurons[-1]))\n",
        "        self.layers = nn.ModuleList(L)\n",
        "        self.numNeurons = numNeurons\n",
        "\n",
        "    def forward(self, X):\n",
        "        for layer in self.layers:\n",
        "            X = layer(X)\n",
        "        return X"
      ],
      "metadata": {
        "id": "5BiYCKNYf1nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 畳み込みニューラルネットの構造と入出力を定義するクラス\n",
        "#\n",
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        L = []\n",
        "        # 畳み込み層1\n",
        "        L.append(nn.Conv2d(1, 16, 5)) # output: [16, 24, 24]\n",
        "        L.append(nn.ReLU())\n",
        "        # 畳み込み層2\n",
        "        L.append(nn.Conv2d(16, 32, 3))  # output: [32, 22, 22]\n",
        "        L.append(nn.ReLU())\n",
        "        # プーリング層\n",
        "        L.append(nn.MaxPool2d(2)) # output: [32, 11, 11]\n",
        "        # 全結合層1\n",
        "        L.append(nn.Flatten()) # 32x11x11 = 3872\n",
        "        L.append(nn.Linear(3872, 400))\n",
        "        # 全結合層2（出力層）\n",
        "        L.append(nn.Linear(400, 10))\n",
        "        self.layers = nn.ModuleList(L)\n",
        "\n",
        "    def forward(self, X):\n",
        "        for layer in self.layers:\n",
        "            X = layer(X)\n",
        "        return X"
      ],
      "metadata": {
        "id": "1yyN9ckpf3NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習の関数\n",
        "#\n",
        "def train(model, lossFunc, optimizer, dl):\n",
        "    loss_sum = 0.0\n",
        "    ncorrect = 0\n",
        "    n = 0\n",
        "    for i, (X, lab) in enumerate(dl):\n",
        "        X, lab = X.to(device), lab.to(device)\n",
        "        Y = model(X)           # 一つのバッチ X を入力して出力 Y を計算\n",
        "        loss = lossFunc(Y, lab) # 正解ラベル lab に対する loss を計算\n",
        "        optimizer.zero_grad()   # 勾配をリセット\n",
        "        loss.backward()         # 誤差逆伝播でパラメータ更新量を計算\n",
        "        optimizer.step()         # パラメータを更新\n",
        "        n += len(X)\n",
        "        loss_sum += loss.item()  # 損失関数の値\n",
        "        ncorrect += (Y.argmax(dim=1) == lab).sum().item()  # 正解数\n",
        "\n",
        "    return loss_sum/n, ncorrect/n"
      ],
      "metadata": {
        "id": "XNSSHTixf5pW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 損失関数や識別率の値を求める関数\n",
        "#\n",
        "@torch.no_grad()\n",
        "def evaluate(model, lossFunc, dl):\n",
        "    loss_sum = 0.0\n",
        "    ncorrect = 0\n",
        "    n = 0\n",
        "    for i, (X, lab) in enumerate(dl):\n",
        "        X, lab = X.to(device), lab.to(device)\n",
        "        Y = model(X)           # 一つのバッチ X を入力して出力 Y を計算\n",
        "        loss = lossFunc(Y, lab)  # 正解ラベル lab に対する loss を計算\n",
        "        n += len(X)\n",
        "        loss_sum += loss.item() # 損失関数の値\n",
        "        ncorrect += (Y.argmax(dim=1) == lab).sum().item()  # 正解数\n",
        "\n",
        "    return loss_sum/n, ncorrect/n"
      ],
      "metadata": {
        "id": "2LZ8pkoRf7eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 実験"
      ],
      "metadata": {
        "id": "sW_x0jaCgF5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のコードセルでは，データ読み込みの処理を行う仕組みを用意する．"
      ],
      "metadata": {
        "id": "4THjEmVagUcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データ読み込みの仕組みを作る\n",
        "dsL = MMDataset(XL, yL)\n",
        "dsT = MMDataset(XT, yT)\n",
        "dlL = DataLoader(dsL, batch_size=100, shuffle=True)\n",
        "dlT = DataLoader(dsT, batch_size=100, shuffle=False)"
      ],
      "metadata": {
        "id": "CQHhvaZzgCiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のコードセルを実行すると，ニューラルネットモデルが作られ， `net` という変数がそれを指す．\n",
        "\n",
        "```\n",
        "net = ...\n",
        "```\n",
        "\n",
        "の行のコメントの付け方を変えれば，モデルの構造を変えることができる．"
      ],
      "metadata": {
        "id": "TzbRloFRgeFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ネットワークモデルの定義\n",
        "net = MLP([784, 10]).to(device)                # ロジスティック回帰\n",
        "#net = MLP([784, 1000, 10]).to(device)         #2層（中間層1層）の階層型ニューラルネット\n",
        "#net = MLP([784, 1000, 1000, 10]).to(device)  #3層（中間層2層）の階層型ニューラルネット\n",
        "#net = CNN().to(device)                          # 畳み込みニューラルネット\n",
        "\n",
        "# ネットワークの構造を表示\n",
        "torchsummary.summary(net, (1, 28, 28))\n",
        "\n",
        "# 損失関数（交差エントロピー） とパラメータ最適化器の設定\n",
        "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "hgCii6IJgRVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のコードセルを実行すると，学習とテストが行われる．\n",
        "\n",
        "【参考】 Google Colab （無料ユーザ） での実行時間\n",
        "- CPU\n",
        "    - `net = MLP([784, 1000, 10]).to(device)`: 2分\n",
        "    - `net = MLP([784, 1000, 1000, 10]).to(device)`: 3分\n",
        "    - `net = CNN().to(device)`: 9分\n",
        "- GPU (T4 GPU)\n",
        "    - `net = MLP([784, 1000, 10]).to(device)`: 24秒\n",
        "    - `net = MLP([784, 1000, 1000, 10]).to(device)`: 26秒\n",
        "    - `net = CNN().to(device)`: 31秒\n"
      ],
      "metadata": {
        "id": "iA5ZuavEhMKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習の繰り返し回数\n",
        "nepoch = 30\n",
        "\n",
        "# 学習\n",
        "L = []\n",
        "print(f'学習データ数: {len(dsL)}  テストデータ数: {len(dsT)}')\n",
        "print()\n",
        "print('# epoch  lossL  lossT  rateL  rateT')\n",
        "for t in range(1, nepoch+1):\n",
        "    lossL, rateL = train(net, loss_func, optimizer, dlL)\n",
        "    lossT, rateT = evaluate(net, loss_func, dlT)\n",
        "    L.append([t, lossL, lossT, rateL, rateT])\n",
        "    if (t < 10) or (t % 10 == 0):\n",
        "        print(f'{t}   {lossL:.5f}   {lossT:.5f}   {rateL:.4f}   {rateT:.4f}')\n",
        "\n",
        "# 学習曲線の表示\n",
        "data = np.array(L)\n",
        "fig, ax = plt.subplots(1, 2, facecolor='white', figsize=(12, 4))\n",
        "ax[0].plot(data[:, 0], data[:, 1], '.-', label='loss for training data')\n",
        "ax[0].plot(data[:, 0], data[:, 2], '.-', label='loss for test data')\n",
        "ax[0].axhline(0.0, color='gray')\n",
        "ax[0].set_ylim(-0.05, 1.0)\n",
        "ax[0].legend()\n",
        "ax[0].set_title(f'loss')\n",
        "ax[1].plot(data[:, 0], data[:, 3], '.-', label='accuracy for training data')\n",
        "ax[1].plot(data[:, 0], data[:, 4], '.-', label='accuracy for test data')\n",
        "ax[1].axhline(1.0, color='gray')\n",
        "ax[1].set_ylim(0.8, 1.025)\n",
        "ax[1].legend()\n",
        "ax[1].set_title(f'accuracy')\n",
        "plt.show()\n",
        "\n",
        "# 学習後の損失と識別率\n",
        "loss2, rrate = evaluate(net, loss_func, dlL)\n",
        "print(f'# lossL: {loss2:.5f}  rateL: {rrate:.4f}', end='   ')\n",
        "loss2, rrate = evaluate(net, loss_func, dlT)\n",
        "print(f'# lossT: {loss2:.5f}  rateT: {rrate:.4f}')"
      ],
      "metadata": {
        "id": "skxDVkr4hJ5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 例2: VGG16"
      ],
      "metadata": {
        "id": "auS1JdchjE-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のリンク先に，2023年度「機械学習I/II」第15回の notebook がある．\n",
        "\n",
        "https://github.com/takatakamanbou/ML/blob/2023/ex15notebookC.ipynb\n",
        "\n",
        "この notebook を入手して，冒頭の「#準備あれこれ」のコードセルを実行してから，「1000種類の物体を識別するニューラルネットを動かしてみよう」の部分を読んで実行しよう（とりあえず「実験その1」まで）．\n"
      ],
      "metadata": {
        "id": "zz01Nqp6khzL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "「実験その1」を実行できたら，その下に次の内容のコードセルを追加して実行してみよう．\n",
        "VGG16 のネットワークの構造を表示させることができる．\n",
        "\n",
        "```\n",
        "import torchsummary\n",
        "torchsummary.summary(vgg16, (3, 224, 224))\n",
        "```"
      ],
      "metadata": {
        "id": "dog3Ha1OkCCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "「実験その2」，「実験その3」もどうぞ．"
      ],
      "metadata": {
        "id": "BX4j62ZGlT0H"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5P7adk87jG3G"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}