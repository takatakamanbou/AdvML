{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/AdvML/blob/2024/AdvML2024_ex01notebookA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzDNLmVS3po"
      },
      "source": [
        "# AdvML ex01notebookA\n",
        "\n",
        "<img width=72 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/AdvML/AdvML-logo.png\"> [この授業のウェブページ](https://www-tlab.math.ryukoku.ac.jp/wiki/?AdvML)\n",
        "\n",
        "※ この notebook は，授業時間中の解説や板書と併用することを想定して作っていますので，説明が不十分なところが多々あります．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ0oDxG3iygx"
      },
      "source": [
        "----\n",
        "## オリエンテーション\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 準備\n",
        "\n",
        "Teams登録，ColabTutorial, etc."
      ],
      "metadata": {
        "id": "hMCm5n2JmZPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 機械学習とは（復習）\n",
        "\n",
        "【参考】 2024年度「機械学習I」第1回 notebookA https://github.com/takatakamanbou/ML/blob/2024/ML2024_ex01notebookA.ipynb"
      ],
      "metadata": {
        "id": "84mXjvbZmimO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### モデル，パラメータ，学習データ"
      ],
      "metadata": {
        "id": "YNyKexpWnCjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 教師あり学習と教師なし学習"
      ],
      "metadata": {
        "id": "h-9c3QrLnJfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 線形回帰と最小二乗法\n",
        "---"
      ],
      "metadata": {
        "id": "-PLcr3DDtLES"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk3ZJYzTiygy"
      },
      "source": [
        "---\n",
        "#### 準備\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVAnXU0Wiygy"
      },
      "outputs": [],
      "source": [
        "# 準備あれこれ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行すると，とあるデータを Pandas の DataFrame として読み込みます．\n",
        "ここで読み込んでいるデータは，\n",
        "\n",
        "「Pythonで理解する統計解析の基礎」 谷合廣紀，辻 真吾，技術評論社，2018.\n",
        "\n",
        "に掲載されているものです．以下の GitHub サイトで公開されています．\n",
        "https://github.com/ghmagazine/python_stat_sample"
      ],
      "metadata": {
        "id": "gtwuqjByt8XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データの読み込み\n",
        "df = pd.read_csv('https://github.com/ghmagazine/python_stat_sample/raw/master/data/ch12_scores_reg.csv')\n",
        "df.drop(columns='通学方法', inplace=True)\n",
        "df"
      ],
      "metadata": {
        "id": "djVvht0JzJo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このデータは，とある授業の受講者20名について，「小テスト」と「期末テスト」の点数，および各受講者の「期末テスト」前日の「睡眠時間」という3つのデータを集めたものとなっています（元のデータにはこれ以外に「通学方法」というのもありますが，ここでは省いています）．\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "euU8_EhW0kb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 問題設定"
      ],
      "metadata": {
        "id": "hY9UUgOEuZWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$D$ 個の値 $x_1, x_2, \\ldots, x_D$ から一つの実数値 $y$ が定まるようなデータがある．\n",
        "それらの間の関係を\n",
        "\n",
        "$$\n",
        "y = w_0 + w_1x_1 + w_2x_2 + \\cdots + w_Dx_D \\qquad (1)\n",
        "$$\n",
        "\n",
        "という式でモデル化する（線形回帰モデル）．以降の式の見通しをよくするために，$1, x_1, x_2, \\ldots, x_D$ という $(D+1)$ 個の値をならべた $(D+1)$ 次元ベクトルを\n",
        "\n",
        "$$\n",
        "\\mathbf{x} = (1, x_1, x_2, \\ldots, x_D)\n",
        "$$\n",
        "\n",
        "と表し（先頭に$1$があることに注意），$(D+1)$個のパラメータをならべた $(D+1)$ 次元ベクトルを\n",
        "\n",
        "$$\n",
        "\\mathbf{w} = (w_0, w_1, w_2, \\ldots, w_D)\n",
        "$$\n",
        "\n",
        "と表すことにする．こうしておくと，式$(1)$のモデルをより簡単に\n",
        "\n",
        "$$\n",
        "y = f(\\mathbf{x}) = \\mathbf{w}\\cdot\\mathbf{x} \\qquad (2)\n",
        "$$\n",
        "\n",
        "と書ける．\n",
        "\n",
        "\n",
        "$N$個のデータ\n",
        "\n",
        "\n",
        "$$\n",
        "(\\mathbf{x}_1, y_1), (\\mathbf{x}_2, y_2),\\ldots , (\\mathbf{x}_N, y_N)\n",
        "$$\n",
        "が与えられ．ただし，$\\mathbf{x}_n$ は上述のように$1$と$D$個の値をならべた$(D+1)$次元ベクトルであり，$y_n$ はこのデータに対する $y$ の値の正解である（$n=1,2,\\ldots, N$）．\n",
        "\n",
        "このとき，$f(\\mathbf{x}_n)$ とその正解の値 $y_n$ との間の二乗誤差の和\n",
        "$$\n",
        "\\sum_{n=1}^{N}(y_n - f(\\mathbf{x}_n))^2 =\\sum_{n=1}^{N}(y_n - \\mathbf{w}\\cdot\\mathbf{x}_n)^2 \\qquad (3)\n",
        "$$\n",
        "を最小にするパラメータ $\\mathbf{w}$ を求めたい．"
      ],
      "metadata": {
        "id": "DBGLuKwUutd6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "このように，回帰モデルを仮定し，モデル出力とその正解との間の二乗誤差を最小化することでモデルパラメータを求める方法を，**最小二乗法** (Least Squares Method) という．"
      ],
      "metadata": {
        "id": "mZ5UAZk2yEwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 正規方程式\n",
        "\n",
        "上述の線形回帰の場合，二乗誤差を最小にするパラメータは，正規方程式と呼ばれる連立方程式の解として得られる．"
      ],
      "metadata": {
        "id": "14lr_2avxVaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(step1) 誤差関数 $E(\\mathbf{w})$ を次のように定義する．\n",
        "\n",
        "$$\n",
        "E(\\mathbf{w}) = \\frac{1}{2}\\sum_{n=1}^N (y_n - \\mathbf{w}\\cdot\\mathbf{x}_n)^2\n",
        " \\qquad (4)$$"
      ],
      "metadata": {
        "id": "xeZlluY7zC0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(step2) $E(\\mathbf{w})$ が最小となるパラメータを求めるために，これを $w_d$ ($d = 0, 1, 2, \\ldots, D$) のそれぞれで偏微分したものを計算する．\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\frac{\\partial E(\\mathbf{w})}{\\partial w_d} &= ...\\\\\n",
        "&= ...\\\\\n",
        "&= \\sum_{n=1}^N (y_n - \\mathbf{w}\\cdot\\mathbf{x}_n)(-x_{n,d})\\qquad (d = 0, 1, 2, \\ldots, D) \\qquad (5)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "$\\mathbf{x}_n$ の $0$ 番目の要素 $x_{n,0}$ は常に $1$ であることに注意．"
      ],
      "metadata": {
        "id": "Wl9l9T8ZzMLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(step3)\n",
        "$\\frac{\\partial E(\\mathbf{w})}{\\partial w_d} = 0$ とすると，次の式が得られる．\n",
        "\n",
        "$$\n",
        "\\begin{pmatrix}\n",
        "\\sum x_{n,0}\\mathbf{w}\\cdot\\mathbf{x}_n \\\\\n",
        "\\sum x_{n,1}\\mathbf{w}\\cdot\\mathbf{x}_n \\\\\n",
        "\\vdots \\\\\n",
        "\\sum x_{n,D}\\mathbf{w}\\cdot\\mathbf{x}_n\n",
        "\\end{pmatrix} =\n",
        "\\begin{pmatrix}\n",
        "\\sum x_{n,0}y_n \\\\ \\sum x_{n,1}y_n\\\\ \\vdots \\\\ \\sum x_{n,D}y_n\n",
        "\\end{pmatrix} \\qquad (6)\n",
        "$$"
      ],
      "metadata": {
        "id": "W3PPb8tmz9SZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "この式は，$(D+1)$ 個の未知数 $w_0, w_1, \\ldots, w_D$ に対して $(D+1)$ 個の式から成る連立方程式である．\n",
        "これが正規方程式だが，より見通しをよくするために，行列を使ってこの式を書き直す．\n",
        "\n",
        "まず，ベクトル $\\mathbf{x}_n$ を行ベクトル（要素が行方向に並んだベクトル）とみなして，それらを列方向に並べた行列を $X$ とする．\n",
        "\n",
        "$$\n",
        "X = \\begin{pmatrix}\n",
        "\\mathbf{x}_1\\\\\n",
        "\\mathbf{x}_2\\\\\n",
        "\\vdots\\\\\n",
        "\\mathbf{x}_N\\\\\n",
        "\\end{pmatrix}\n",
        "=\n",
        "\\begin{pmatrix}\n",
        "1 & x_{1,1} & x_{1,2} & \\cdots & x_{1,D}\\\\\n",
        "1 & x_{2,1} & x_{2,2} & \\cdots & x_{2,D}\\\\\n",
        "& & \\vdots\\\\\n",
        "1 & x_{N,1} & x_{N,2} & \\cdots & x_{N,D}\\\\\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "$X$ は $N\\times(D+1)$ 行列である．．次に，出力の正解の値 $y_1, y_2, \\ldots, y_N$ を列方向に並べた行列を $Y$ とする．\n",
        "\n",
        "\n",
        "$$\n",
        "Y = \\begin{pmatrix}\n",
        "y_1\\\\ y_2 \\\\ \\vdots \\\\ y_N\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "$Y$ は $N\\times 1$ 行列．"
      ],
      "metadata": {
        "id": "Pm1ZnW_T0Ci8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(step4) 式$(6)$の右辺が $X^{\\top}Y$ と等しいことを示す．"
      ],
      "metadata": {
        "id": "UUM9dsMP07V0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(step5) 式$(6)$の左辺が $X^{\\top}X\\mathbf{w}^{\\top}$ と等しいことを示す．\n",
        "ここで $\\mathbf{w}$ は， パラメータ $w_0, w_1, \\ldots, w_D$ を次のようにならべた $1\\times (D+1)$ 行列である．\n",
        "\n",
        "$$\n",
        "\\mathbf{w} = \\begin{pmatrix}\n",
        "w_0 & w_1 & \\ldots & w_D\n",
        "\\end{pmatrix}\n",
        "$$"
      ],
      "metadata": {
        "id": "1p-tmpnh1nFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "以上より，式 $(4)$ を最小にするパラメータ $\\mathbf{w}$ は，次の正規方程式の解である．\n",
        "\n",
        "$$\n",
        "\\mathbf{w}X^{\\top}X\n",
        "= Y^{\\top}X\n",
        "$$\n",
        "\n",
        "両辺を転置して，次のようにも書ける\n",
        "\n",
        "$$\n",
        "X^{\\top}X\\mathbf{w}^{\\top}\n",
        "= X^{\\top}Y \\qquad (7)\n",
        "$$"
      ],
      "metadata": {
        "id": "iUugfe4x24iK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 例題: (小テスト, 睡眠時間)から期末テストの点数を予測する"
      ],
      "metadata": {
        "id": "W4YvYrXB3nP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# N x (D+1) 行列 X をつくる\n",
        "X_raw = df.loc[:, ['小テスト', '睡眠時間']].to_numpy()\n",
        "X = np.vstack([np.ones(len(X_raw)), X_raw.T]).T\n",
        "print(X)\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "ZMyyMcaNt5kG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 正解の値をならべたベクトル Y をつくる\n",
        "Y = df['期末テスト'].to_numpy()\n",
        "print(Y)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "id": "6B0j-1vk4B5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 正規方程式を構成する行列を求める\n",
        "XTX = X.T @ X  # 正規方程式の左辺の(D+1)x(D+1)の行列\n",
        "XTY = X.T @ Y    # 正規方程式の右辺の(D+1)x1の行列\n",
        "print(XTX)\n",
        "print(XTX.shape)\n",
        "print()\n",
        "print(XTY)\n",
        "print(XTY.shape)"
      ],
      "metadata": {
        "id": "CG_1KkJO4IG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 正規方程式を解く\n",
        "w = np.linalg.solve(XTX, XTY) # 連立方程式を解く\n",
        "print(f'{len(w)}個のパラメータの値は')\n",
        "print(w)"
      ],
      "metadata": {
        "id": "mgM_8ybp4V2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "【参考】 [NumPy documentation](https://numpy.org/doc/stable/index.html) の中の [np.linalg.solve](https://numpy.org/doc/stable/reference/generated/numpy.linalg.solve.html) のページ"
      ],
      "metadata": {
        "id": "H7oDk-Bx918z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 予測値の計算\n",
        "Yt = X @ w\n",
        "\n",
        "print(' 小テスト 睡眠 期末の予測値  正解')\n",
        "for n in range(len(X)):\n",
        "    print(f'{n:2d}   {X[n, 1]}   {X[n, 2]}   {Yt[n]:.1f}   {Y[n]}')"
      ],
      "metadata": {
        "id": "e_0Jvx6z4iKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 機械学習と最適化\n",
        "---"
      ],
      "metadata": {
        "id": "YI1bJIqP6xP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "多くの機械学習の問題は，目的関数を最適化する問題として定式化できる\n",
        "\n",
        "問題に応じて，次のものを決めることになる:\n",
        "データの形式（どんな入力？どんな出力？） / モデル / 目的関数 / 最適化の手法"
      ],
      "metadata": {
        "id": "lg36NA1t67EJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BNfHm6Oz5Dzl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}