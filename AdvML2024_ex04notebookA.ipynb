{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/AdvML/blob/2024/AdvML2024_ex04notebookA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzDNLmVS3po"
      },
      "source": [
        "# AdvML ex04notebookA\n",
        "\n",
        "<img width=72 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/AdvML/AdvML-logo.png\"> [この授業のウェブページ](https://www-tlab.math.ryukoku.ac.jp/wiki/?AdvML)\n",
        "\n",
        "※ この notebook は，授業時間中の解説や板書と併用することを想定して作っていますので，説明が不十分なところが多々あります．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ0oDxG3iygx"
      },
      "source": [
        "----\n",
        "## 準備\n",
        "----\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 準備あれこれ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set()\n",
        "\n",
        "# scikit-learn のいろいろ\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Lasso"
      ],
      "metadata": {
        "id": "RjLTO96x2EvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### California Housing Dataset"
      ],
      "metadata": {
        "id": "z2ch9Myp6-h8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "reportA でも使った California Housing Dataset を使う．"
      ],
      "metadata": {
        "id": "jwPNrO697DGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを入手\n",
        "data = fetch_california_housing(as_frame=True)\n",
        "dfX = data['data']\n",
        "dfY = data['target']\n",
        "\n",
        "# 全データの 8 割を学習データとし，残りを検証データとする\n",
        "#   random_state を指定しなければ実行のたびに分割の仕方が変わるので毎回異なる実験結果となるが，\n",
        "#   ここでは一つの値に固定しているで，何度やっても（当然，誰がやっても）同じ条件で実験できる\n",
        "XL, XV, yL, yV = train_test_split(dfX.to_numpy(), dfY.to_numpy(), train_size=0.8, random_state=0)\n",
        "print(XL.shape, yL.shape, XV.shape, yV.shape)"
      ],
      "metadata": {
        "id": "hLP-Oy4m7BWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 標準化\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(XL)\n",
        "print(scaler.mean_) # 平均\n",
        "print(scaler.var_) # 分散\n",
        "\n",
        "# 求めた平均と分散を使って XL, XV を標準化\n",
        "XL2 = scaler.transform(XL)\n",
        "XV2 = scaler.transform(XV)"
      ],
      "metadata": {
        "id": "BCWGLxlj7ieU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ラッソ回帰\n",
        "---"
      ],
      "metadata": {
        "id": "Ks4zvYPr7_Bs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 特徴を選択したい"
      ],
      "metadata": {
        "id": "SkNlLeTN8kfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "線形回帰モデルを学習させると，次のようになる．"
      ],
      "metadata": {
        "id": "OzUdWT4A8wla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 線形回帰モデルの学習\n",
        "model = LinearRegression()\n",
        "regressor = model.fit(XL2, yL)\n",
        "\n",
        "# パラメータ表示用\n",
        "dfW = pd.DataFrame(columns=['alpha', 'const']+list(dfX.columns))\n",
        "dfW['alpha'] = [0.0]\n",
        "dfW['const'] = regressor.intercept_\n",
        "dfW.iloc[0, 2:] = regressor.coef_\n",
        "#dfW.set_index('alpha', inplace=True)\n",
        "\n",
        "# 平均二乗誤差の計算\n",
        "yL_pred = regressor.predict(XL2)\n",
        "msqeL = np.mean((yL_pred - yL)**2)\n",
        "yV_pred = regressor.predict(XV2)\n",
        "msqeV = np.mean((yV_pred - yV)**2)\n",
        "\n",
        "# 出力\n",
        "print(f'msqeL = {msqeL:.4f}  msqeV = {msqeV:.4f}')\n",
        "dfW"
      ],
      "metadata": {
        "id": "zsuKNxew76FI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "この場合，得られたモデルはおよそ\n",
        "\n",
        "$$\n",
        "\\mbox{（住宅価格の予測値）} = 2.07 + 0.82\\times (\\mbox{MedInc}) + 0.12\\times (\\mbox{HouseAge}) + \\cdots +(-0.87)\\times \\mbox{(Longtitude)}  \n",
        "$$\n",
        "\n",
        "という式である．'MedInc' から 'Longtitude' までの8つの変数に対する係数はどれも $0$ ではないので，住宅価格の予測に寄与しているということになる．\n",
        "しかし，これらの変数の中には，住宅価格に大きな影響を与える重要なものもあれば，影響の少ない重要でないものもあるかもしれない．\n",
        "\n",
        "このような問題意識を一般化すると，「与えられた多変量データの中から重要な変数/特徴を見つけ出したい」ということになる．このようなことを行うのが **特徴選択** (**feature selection**) である．\n",
        "\n",
        "特徴選択の方法には様々なものがあるが，ここではその中のひとつであるラッソ回帰を取り上げる．"
      ],
      "metadata": {
        "id": "tts0ki3n9Cio"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### ラッソ回帰とは"
      ],
      "metadata": {
        "id": "isXTpHvqBUhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ラッソ回帰** （**LASSO回帰**, LASSO は \"least absolute shrinkage and selection operator\"の頭文字）は，汎化性能の改善と特徴選択の実現という二つを主な目的とした回帰の手法である．"
      ],
      "metadata": {
        "id": "0iLlstXrE_1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\mathbf{x}$ から $y$ を予測する回帰モデル $f(\\mathbf{x})$ を考える．\n",
        "このモデルの学習のためのデータを $ (\\mathbf{x}_n, y_n)$ ($n = 1, 2, \\ldots, N$) とする．\n",
        "\n",
        "最小二乗法による線形回帰のように，モデルの出力ととその正解の値との間の二乗誤差の和のみを最小化する場合，\n",
        "学習の目的関数は次式のように書けた．\n",
        "\n",
        "$$\n",
        "E(\\mathbf{w}) =\n",
        "\\sum_{n=1}^{N}(y_n - f(\\mathbf{x}_n))^2\n",
        "$$\n",
        "\n",
        "リッジ回帰の場合，モデルパラメータの値の大きさに制約を加えるために，目的関数に次のような正則化項を付加するのだった．\n",
        "\n",
        "$$\n",
        "E(\\mathbf{w}) =\n",
        "\\sum_{n=1}^{N}(y_n - f(\\mathbf{x}_n))^2 + \\alpha ||\\mathbf{w}||^2\n",
        "$$\n",
        "\n",
        "ここで，$\\mathbf{w}$ はモデルパラメータを並べたベクトルである．パラメータ数を $M$ として，$\\mathbf{w} = (w_1, w_2, \\ldots, w_M)$ とおくと，上の式は次のように書き直せる．\n",
        "\n",
        "$$\n",
        "E(\\mathbf{w}) =\n",
        "\\sum_{n=1}^{N}(y_n - f(\\mathbf{x}_n))^2 + \\alpha \\sum_{m=1}^{M}w_m^2\n",
        "$$\n",
        "\n",
        "正則化項は，パラメータの二乗和を小さくする働きをしている．\n"
      ],
      "metadata": {
        "id": "L5qXN5qdBjPL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "これに対して，ラッソ回帰では，パラメータの絶対値の和を小さくする．\n",
        "すなわち，次のような目的関数を最小化する．\n",
        "\n",
        "$$\n",
        "E(\\mathbf{w}) =\n",
        "\\sum_{n=1}^{N}(y_n - f(\\mathbf{x}_n))^2 + \\alpha \\sum_{m=1}^{M}|w_m|\n",
        "$$\n"
      ],
      "metadata": {
        "id": "L63IbhxnESSU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### やってみよう"
      ],
      "metadata": {
        "id": "ncAiznWrFzUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "California Housing Dataset を使ってラッソ回帰の実験をやってみよう．\n",
        "ここでは，[sklearn.linear_model.Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) を用いる．"
      ],
      "metadata": {
        "id": "y7YD9qXNF5bx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 正則化項の係数\n",
        "alpha = 0.01  ### ここを少しずつ大きくしていってみよう\n",
        "\n",
        "# LASSO回帰モデルの学習\n",
        "model = Lasso(alpha=alpha)\n",
        "regressor = model.fit(XL2, yL)\n",
        "\n",
        "# パラメータ表示用\n",
        "dfW = pd.DataFrame(columns=['alpha', 'const']+list(dfX.columns))\n",
        "dfW['alpha'] = [0.0]\n",
        "dfW['const'] = regressor.intercept_\n",
        "dfW.iloc[0, 2:] = regressor.coef_\n",
        "dfW.set_index('alpha', inplace=True)\n",
        "\n",
        "# 平均二乗誤差の計算\n",
        "yL_pred = regressor.predict(XL2)\n",
        "msqeL = np.mean((yL_pred - yL)**2)\n",
        "yV_pred = regressor.predict(XV2)\n",
        "msqeV = np.mean((yV_pred - yV)**2)\n",
        "\n",
        "# 出力\n",
        "print(f'msqeL = {msqeL:.4f}  msqeV = {msqeV:.4f}')\n",
        "dfW"
      ],
      "metadata": {
        "id": "xEBYlhix8tmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "正則化項の係数 `alpha` を大きくしていくと，パラメータの値や平均二乗誤差の値はどのように変化するだろうか．"
      ],
      "metadata": {
        "id": "idQ7rZtYGlm4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行すると，いろいろな `alpha` の設定での実験をまとめて行うことができる．"
      ],
      "metadata": {
        "id": "UoFckRDzHt5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alphaList = np.logspace(-3, 0, num=10)\n",
        "N, D = XL2.shape\n",
        "w = np.empty((len(alphaList), D))\n",
        "\n",
        "dfW = pd.DataFrame(columns=['alpha', 'msqeL', 'msqeV', 'const']+list(dfX.columns))\n",
        "dfW['alpha'] = alphaList\n",
        "\n",
        "for i, alpha in enumerate(alphaList):\n",
        "    model = Lasso(alpha=alpha)\n",
        "    regressor = model.fit(XL2, yL)\n",
        "    dfW.iloc[i, 1] = np.mean((regressor.predict(XL2) - yL)**2)\n",
        "    dfW.iloc[i, 2] = np.mean((regressor.predict(XV2) - yV)**2)\n",
        "    dfW.iloc[i, 3] = regressor.intercept_\n",
        "    dfW.iloc[i, 4:] = regressor.coef_\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
        "w = dfW.iloc[:, 3:].to_numpy()\n",
        "for d in range(D):\n",
        "    ax.plot(alphaList, w[:, d], marker='o')\n",
        "ax.set_xscale('log')\n",
        "ax.set_ylim(-1.0, 1.0)\n",
        "ax.set_xlabel(r'$\\alpha$')\n",
        "plt.show()\n",
        "\n",
        "dfW.set_index('alpha', inplace=True)\n",
        "dfW"
      ],
      "metadata": {
        "id": "f6TrY-eQGTvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "住宅価格の予測のために重要な特徴を（定数項を除いて）4つあげるとすると，どれだろう．"
      ],
      "metadata": {
        "id": "O48IDqnaIM8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### いろいろ\n",
        "\n"
      ],
      "metadata": {
        "id": "srC1O0NXJUYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### スパース\n",
        "\n",
        "**スパース** (sparse)\n"
      ],
      "metadata": {
        "id": "VZIKdo9vJha4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### $p$-ノルム\n",
        "\n",
        "$ \\mathbf{x} = (x_1, x_2, \\ldots, x_M)$ のとき，\n",
        "\n",
        "$$\n",
        "||\\mathbf{x}||_p = \\left( \\sum_{m=1}^{M} |x_d|^p \\right)^{\\frac{1}{p}}\n",
        "$$\n",
        "\n",
        "を $L^{p}$ ノルムまたは $p$-ノルムという．$p=2$ のときはユークリッドノルム．\n",
        "\n",
        "リッジ回帰はパラメータの $L^2$ ノルム（ユークリッドノルム）を,\n",
        "ラッソ回帰はパラメータの $L^1$ ノルムを制約する．\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\textrm{Ridge:}  E(\\mathbf{w}) &=\n",
        "\\sum_{n=1}^{N}(y_n - f(\\mathbf{x}_n))^2 + \\alpha ||\\mathbf{w}||_2^2\\\\\n",
        "\\textrm{LASSO:} E(\\mathbf{w}) & =\\sum_{n=1}^{N}(y_n - f(\\mathbf{x}_n))^2 + \\alpha ||\\mathbf{w}||_1\\\\\n",
        "\\end{aligned}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "UZXjM5oLJqlq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### なぜ $L^1$ ノルム最小化でスパースになるのか"
      ],
      "metadata": {
        "id": "2z5RXykoLDkk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UeDP3eJzHMNe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}