{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/AdvML/blob/2025/AdvML2025_ex01notebookA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzDNLmVS3po"
      },
      "source": [
        "# AdvML ex01notebookA\n",
        "\n",
        "<img width=72 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/AdvML/AdvML-logo.png\"> [この授業のウェブページ](https://www-tlab.math.ryukoku.ac.jp/wiki/?AdvML)\n",
        "\n",
        "※ この notebook は，授業時間中の解説や板書と併用することを想定して作っていますので，説明が不十分なところが多々あります．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ0oDxG3iygx"
      },
      "source": [
        "----\n",
        "## オリエンテーション\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 準備\n",
        "\n",
        "Teams登録，ColabTutorial, etc."
      ],
      "metadata": {
        "id": "hMCm5n2JmZPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 機械学習とは（復習）\n",
        "\n",
        "【参考】 2025年度「機械学習I」第1回 notebookA https://github.com/takatakamanbou/ML/blob/2025/ML2025_ex01notebookA.ipynb"
      ],
      "metadata": {
        "id": "84mXjvbZmimO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### モデル，パラメータ，学習データ"
      ],
      "metadata": {
        "id": "YNyKexpWnCjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 教師あり学習と教師なし学習"
      ],
      "metadata": {
        "id": "h-9c3QrLnJfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 線形回帰と最小二乗法（復習）\n",
        "---\n",
        "\n",
        "【参考】2025年度「機械学習I」第2回 notebookA https://github.com/takatakamanbou/ML/blob/2025/ML2025_ex02notebookA.ipynb"
      ],
      "metadata": {
        "id": "-PLcr3DDtLES"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk3ZJYzTiygy"
      },
      "source": [
        "---\n",
        "#### 準備\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVAnXU0Wiygy"
      },
      "outputs": [],
      "source": [
        "# 準備あれこれ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set_theme()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行すると，とあるデータを Pandas の DataFrame として読み込みます．\n",
        "ここで読み込んでいるデータは，\n",
        "\n",
        "「Pythonで理解する統計解析の基礎」 谷合廣紀，辻 真吾，技術評論社，2018.\n",
        "\n",
        "に掲載されているものです．以下の GitHub サイトで公開されています．\n",
        "https://github.com/ghmagazine/python_stat_sample"
      ],
      "metadata": {
        "id": "gtwuqjByt8XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データの読み込み\n",
        "df = pd.read_csv('https://github.com/ghmagazine/python_stat_sample/raw/master/data/ch12_scores_reg.csv')\n",
        "df.drop(columns='通学方法', inplace=True)\n",
        "df"
      ],
      "metadata": {
        "id": "djVvht0JzJo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このデータは，とある授業の受講者20名について，「小テスト」と「期末テスト」の点数，および各受講者の「期末テスト」前日の「睡眠時間」という3つのデータを集めたものとなっています（元のデータにはこれ以外に「通学方法」というのもありますが，ここでは省いています）．\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "euU8_EhW0kb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 問題設定"
      ],
      "metadata": {
        "id": "hY9UUgOEuZWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$D$ 個の値 $x_1, x_2, \\ldots, x_D$ から一つの実数値 $y$ が定まるようなデータがある．\n",
        "それらの間の関係を\n",
        "\n",
        "$$\n",
        "y = w_0 + w_1x_1 + w_2x_2 + \\cdots + w_Dx_D \\qquad (1)\n",
        "$$\n",
        "\n",
        "という式でモデル化する（線形回帰モデル）．以降の式の見通しをよくするために，$1, x_1, x_2, \\ldots, x_D$ という $(D+1)$ 個の値をならべた $(D+1)$ 次元ベクトルを\n",
        "\n",
        "$$\n",
        "\\pmb{x} = (1, x_1, x_2, \\ldots, x_D)\n",
        "$$\n",
        "\n",
        "と表し（先頭に$1$があることに注意），$(D+1)$個のパラメータをならべた $(D+1)$ 次元ベクトルを\n",
        "\n",
        "$$\n",
        "\\pmb{w} = (w_0, w_1, w_2, \\ldots, w_D)\n",
        "$$\n",
        "\n",
        "と表すことにする．こうしておくと，式$(1)$のモデルをより簡単に\n",
        "\n",
        "$$\n",
        "y = f(\\pmb{x}) = \\pmb{w}\\cdot\\pmb{x} \\qquad (2)\n",
        "$$\n",
        "\n",
        "と書ける．\n",
        "\n",
        "\n",
        "$N$個のデータ\n",
        "\n",
        "\n",
        "$$\n",
        "(\\pmb{x}_1, y_1), (\\pmb{x}_2, y_2),\\ldots , (\\pmb{x}_N, y_N)\n",
        "$$\n",
        "が与えられ．ただし，$\\pmb{x}_n$ は上述のように$1$と$D$個の値をならべた$(D+1)$次元ベクトルであり，$y_n$ はこのデータに対する $y$ の値の正解である（$n=1,2,\\ldots, N$）．\n",
        "\n",
        "このとき，$f(\\pmb{x}_n)$ とその正解の値 $y_n$ との間の二乗誤差の和\n",
        "$$\n",
        "\\sum_{n=1}^{N}(y_n - f(\\pmb{x}_n))^2 =\\sum_{n=1}^{N}(y_n - \\pmb{w}\\cdot\\pmb{x}_n)^2 \\qquad (3)\n",
        "$$\n",
        "を最小にするパラメータ $\\pmb{w}$ を求めたい．"
      ],
      "metadata": {
        "id": "DBGLuKwUutd6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "このように，回帰モデルを仮定し，モデル出力とその正解との間の二乗誤差を最小化することでモデルパラメータを求める方法を，**最小二乗法** (Least Squares Method) という．"
      ],
      "metadata": {
        "id": "mZ5UAZk2yEwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 正規方程式\n",
        "\n",
        "上述の線形回帰の場合，二乗誤差を最小にするパラメータは，正規方程式と呼ばれる連立方程式の解として得られる．"
      ],
      "metadata": {
        "id": "14lr_2avxVaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(step1) 誤差関数 $E(\\pmb{w})$ を次のように定義する．\n",
        "\n",
        "$$\n",
        "E(\\pmb{w}) = \\frac{1}{2}\\sum_{n=1}^N (y_n - \\pmb{w}\\cdot\\pmb{x}_n)^2\n",
        " \\qquad (4)$$"
      ],
      "metadata": {
        "id": "xeZlluY7zC0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(step2) $E(\\pmb{w})$ が最小となるパラメータを求めるために，これを $w_d$ ($d = 0, 1, 2, \\ldots, D$) のそれぞれで偏微分したものを計算する．\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\frac{\\partial E(\\pmb{w})}{\\partial w_d} &= ...\\\\\n",
        "&= ...\\\\\n",
        "&= \\sum_{n=1}^N (y_n - \\pmb{w}\\cdot\\pmb{x}_n)(-x_{n,d})\\qquad (d = 0, 1, 2, \\ldots, D) \\qquad (5)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "$\\pmb{x}_n$ の $0$ 番目の要素 $x_{n,0}$ は常に $1$ であることに注意．"
      ],
      "metadata": {
        "id": "Wl9l9T8ZzMLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(step3)\n",
        "$\\frac{\\partial E(\\pmb{w})}{\\partial w_d} = 0$ とすると，次の式が得られる．\n",
        "\n",
        "$$\n",
        "\\begin{pmatrix}\n",
        "\\sum x_{n,0}\\pmb{w}\\cdot\\pmb{x}_n \\\\\n",
        "\\sum x_{n,1}\\pmb{w}\\cdot\\pmb{x}_n \\\\\n",
        "\\vdots \\\\\n",
        "\\sum x_{n,D}\\pmb{w}\\cdot\\pmb{x}_n\n",
        "\\end{pmatrix} =\n",
        "\\begin{pmatrix}\n",
        "\\sum x_{n,0}y_n \\\\ \\sum x_{n,1}y_n\\\\ \\vdots \\\\ \\sum x_{n,D}y_n\n",
        "\\end{pmatrix} \\qquad (6)\n",
        "$$"
      ],
      "metadata": {
        "id": "W3PPb8tmz9SZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "この式は，$(D+1)$ 個の未知数 $w_0, w_1, \\ldots, w_D$ に対して $(D+1)$ 個の式から成る連立方程式である．\n",
        "これが正規方程式だが，より見通しをよくするために，行列を使ってこの式を書き直す．\n",
        "\n",
        "まず，ベクトル $\\pmb{x}_n$ を行ベクトル（要素が行方向に並んだベクトル）とみなして，それらを列方向に並べた行列を $X$ とする．\n",
        "\n",
        "$$\n",
        "X = \\begin{pmatrix}\n",
        "\\pmb{x}_1\\\\\n",
        "\\pmb{x}_2\\\\\n",
        "\\vdots\\\\\n",
        "\\pmb{x}_N\\\\\n",
        "\\end{pmatrix}\n",
        "=\n",
        "\\begin{pmatrix}\n",
        "1 & x_{1,1} & x_{1,2} & \\cdots & x_{1,D}\\\\\n",
        "1 & x_{2,1} & x_{2,2} & \\cdots & x_{2,D}\\\\\n",
        "& & \\vdots\\\\\n",
        "1 & x_{N,1} & x_{N,2} & \\cdots & x_{N,D}\\\\\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "$X$ は $N\\times(D+1)$ 行列である．．次に，出力の正解の値 $y_1, y_2, \\ldots, y_N$ を列方向に並べた行列を $Y$ とする．\n",
        "\n",
        "\n",
        "$$\n",
        "Y = \\begin{pmatrix}\n",
        "y_1\\\\ y_2 \\\\ \\vdots \\\\ y_N\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "$Y$ は $N\\times 1$ 行列．"
      ],
      "metadata": {
        "id": "Pm1ZnW_T0Ci8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(step4) 式$(6)$の右辺が $X^{\\top}Y$ と等しいことを示す．"
      ],
      "metadata": {
        "id": "UUM9dsMP07V0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(step5) 式$(6)$の左辺が $X^{\\top}X\\pmb{w}^{\\top}$ と等しいことを示す．\n",
        "ここで $\\pmb{w}$ は， パラメータ $w_0, w_1, \\ldots, w_D$ を次のようにならべた $1\\times (D+1)$ 行列である．\n",
        "\n",
        "$$\n",
        "\\pmb{w} = \\begin{pmatrix}\n",
        "w_0 & w_1 & \\ldots & w_D\n",
        "\\end{pmatrix}\n",
        "$$"
      ],
      "metadata": {
        "id": "1p-tmpnh1nFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "以上より，式 $(4)$ を最小にするパラメータ $\\pmb{w}$ は，次の正規方程式の解である．\n",
        "\n",
        "$$\n",
        "\\pmb{w}X^{\\top}X\n",
        "= Y^{\\top}X\n",
        "$$\n",
        "\n",
        "両辺を転置して，次のようにも書ける\n",
        "\n",
        "$$\n",
        "X^{\\top}X\\pmb{w}^{\\top}\n",
        "= X^{\\top}Y \\qquad (7)\n",
        "$$"
      ],
      "metadata": {
        "id": "iUugfe4x24iK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 例題: (小テスト, 睡眠時間)から期末テストの点数を予測する"
      ],
      "metadata": {
        "id": "W4YvYrXB3nP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# N x (D+1) 行列 X をつくる\n",
        "X_raw = df.loc[:, ['小テスト', '睡眠時間']].to_numpy()\n",
        "X = np.vstack([np.ones(len(X_raw)), X_raw.T]).T\n",
        "print(X)\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "ZMyyMcaNt5kG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 正解の値をならべたベクトル Y をつくる\n",
        "Y = df['期末テスト'].to_numpy()\n",
        "print(Y)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "id": "6B0j-1vk4B5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 正規方程式を構成する行列を求める\n",
        "XTX = X.T @ X  # 正規方程式の左辺の(D+1)x(D+1)の行列\n",
        "XTY = X.T @ Y    # 正規方程式の右辺の(D+1)x1の行列\n",
        "print(XTX)\n",
        "print(XTX.shape)\n",
        "print()\n",
        "print(XTY)\n",
        "print(XTY.shape)"
      ],
      "metadata": {
        "id": "CG_1KkJO4IG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 正規方程式を解く\n",
        "w = np.linalg.solve(XTX, XTY) # 連立方程式を解く\n",
        "print(f'{len(w)}個のパラメータの値は')\n",
        "print(w)"
      ],
      "metadata": {
        "id": "mgM_8ybp4V2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "【参考】 [NumPy documentation](https://numpy.org/doc/stable/index.html) の中の [np.linalg.solve](https://numpy.org/doc/stable/reference/generated/numpy.linalg.solve.html) のページ"
      ],
      "metadata": {
        "id": "H7oDk-Bx918z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 予測値の計算\n",
        "Yt = X @ w\n",
        "\n",
        "print(' 小テスト 睡眠 期末の予測値  正解')\n",
        "for n in range(len(X)):\n",
        "    print(f'{n:2d}   {X[n, 1]}   {X[n, 2]}   {Yt[n]:.1f}   {Y[n]}')"
      ],
      "metadata": {
        "id": "e_0Jvx6z4iKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj9xmluTZuD1"
      },
      "source": [
        "----\n",
        "## 汎化と過適合（復習）\n",
        "----\n",
        "\n",
        "【参考】2025年度「機械学習I」第2回 notebookB https://github.com/takatakamanbou/ML/blob/2025/ML2025_ex02notebookB.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 多項式回帰\n",
        "\n",
        "「汎化と過適合」の説明で使う道具として，1入力1出力のデータに多項式を当てはめる **多項式回帰** を導入する．"
      ],
      "metadata": {
        "id": "2wnmuzmQ16t6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**［多項式回帰（最小二乗法による多項式当てはめ）の問題設定］**\n",
        "\n",
        "変数 $x$ と $y$ の値のペア $N$ 組から成るデータ\n",
        "$$\n",
        "(x_1, y_1), (x_2, y_2), \\ldots, (x_N, y_N)\n",
        "$$\n",
        "がある．変数 $x$ の値から $y$ の値が決まるものとし，そのモデルとして $(D+1)$ 個のパラメータをもつ $D$ 次多項式\n",
        "\n",
        "$$\n",
        "y = f(x) = w_0 + w_1 x + w_2x^2 + \\cdots + w_Dx^{D} \\qquad (1)\n",
        "$$\n",
        "\n",
        "を考える．\n",
        "\n",
        "\n",
        "このとき，モデルの出力 $f(x_n)$ とその正解の値 $y_n$ との間の二乗誤差の和\n",
        "$$\n",
        "\\sum_{n=1}^{N}(y_n - f(x_n))^2\n",
        "$$\n",
        "を最小にするパラメータ $w_0, w_1, \\ldots, w_D$ を求めたい．\n",
        "\n"
      ],
      "metadata": {
        "id": "BSD8USkbK3jD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "この多項式回帰の問題は，線形回帰（平面当てはめ）の問題をちょこっと変形したものとみなせる．\n",
        "\n",
        "平面当てはめでは，$1, x_1, x_2, \\ldots, x_D$ という $(D+1)$ 個の値をならべた $(D+1)$ 次元ベクトル（$1\\times (D+1)$ 行列）\n",
        "$$\n",
        "\\pmb{x} = (1, x_1, x_2, x_3, \\ldots, x_D)\n",
        "$$\n",
        "を考えたが，そのかわりに\n",
        "$$\n",
        "\\pmb{x} = (1, x, x^2, x^3, \\ldots, x^D)\n",
        "$$\n",
        "としてやれば ok．こうすれば，平面当てはめと同様に$(D+1)$個のパラメータをならべたベクトル（$1\\times (D+1)$ 行列）を\n",
        "$$\n",
        "\\pmb{w} = (w_0, w_1, w_2, \\ldots, w_D)\n",
        "$$\n",
        "として，式$(1)$を\n",
        "$$\n",
        "y = f(\\pmb{x}) = \\pmb{w}\\cdot\\pmb{x} \\qquad (2)\n",
        "$$\n",
        "と表せる．以下，平面当てはめの定式化と同じなので，正規方程式も同じ形になる．\n",
        "\n",
        "つまり，$N\\times(D+1)$ 行列 $X$ と $N\\times 1$ 行列 $Y$ を\n",
        "\n",
        "$$\n",
        "X = \\begin{pmatrix}\n",
        "\\pmb{x}_1\\\\\n",
        "\\pmb{x}_2\\\\\n",
        "\\vdots\\\\\n",
        "\\pmb{x}_N\\\\\n",
        "\\end{pmatrix}\n",
        "=\n",
        "\\begin{pmatrix}\n",
        "1 & x_{1} & x_{1}^{2} & \\cdots & x_{1}^{D}\\\\\n",
        "1 & x_{2} & x_{2}^{2} & \\cdots & x_{2}^{D}\\\\\n",
        "& & \\vdots\\\\\n",
        "1 & x_{N} & x_{N}^{2} & \\cdots & x_{N}^{D}\\\\\n",
        "\\end{pmatrix}\n",
        "\\qquad\n",
        "Y = \\begin{pmatrix}\n",
        "y_1\\\\ y_2 \\\\ \\vdots \\\\ y_N\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "とおくと，二乗誤差を最小にするパラメータ $\\pmb{w}$ は次の正規方程式の解である．\n",
        "\n",
        "$$\n",
        "X^{\\top}X\\pmb{w}^{\\top}\n",
        "= X^{\\top}Y\n",
        "$$\n"
      ],
      "metadata": {
        "id": "xrIKO0QWGZtX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 正弦波の多項式回帰の実験"
      ],
      "metadata": {
        "id": "xMP4BEJO4RjV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 問題"
      ],
      "metadata": {
        "id": "kcvzFrEp7IJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$x$ と $y$ の間の真の関係が $y = h(x) = \\sin{(2\\pi x)} + 1$ という式で表されるときに，区間 $[0, 1]$ で一様分布する $x$ の値が $N$ 個得られ，それぞれの値に対応する $y$ の値も同数得られるとする．それらを $(x_n, y_n)$ ($n = 1, 2, \\ldots, N$) とする．\n",
        "ただし，得られる $y_n$ にはノイズが乗っており，$y_n = h(x_n) + \\epsilon_n$ と表されるものとする．$\\epsilon_n$ は標準偏差 $0.1$ の正規乱数である．\n",
        "\n",
        "$(x_n, y_n)$  ($n = 1, 2, \\ldots, N$) のみが与えられる（$h(x)$ の式やどんなノイズが乗っているかは未知）ときに，$x$ から $y$ の値を予測するモデルを作りたい．\n"
      ],
      "metadata": {
        "id": "QwSFt2MR413-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### データを生成する関数\n",
        "#\n",
        "def generateData(N, trueFunc=False, seed=None, sigma=0.0):\n",
        "\n",
        "    if trueFunc:\n",
        "        x = np.linspace(-0.1, 1.1, num=N)\n",
        "        y = np.sin(2*np.pi*x) + 1\n",
        "    else:\n",
        "        # 乱数生成器\n",
        "        rng = np.random.default_rng(seed)\n",
        "        x = rng.uniform(0.0, 1.0, N)\n",
        "        y = np.sin(2*np.pi*x) + 1 + sigma*rng.standard_normal(N)\n",
        "\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "MtBcrQJmV8_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_true, y_true  = generateData(100, trueFunc=True)\n",
        "x_noisy, y_noisy = generateData(25, sigma=0.1)\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_xlim(-0.1, 1.1)\n",
        "ax.set_ylim(-0.2, 2.2)\n",
        "ax.plot(x_true, y_true, color='blue', label='true function')\n",
        "ax.scatter(x_noisy, y_noisy, color='red', label='noisy data')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3rd04d84mtHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 多項式回帰をやってみよう"
      ],
      "metadata": {
        "id": "MpBSBfug7PR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下の「多項式次数」をいろいろ変えて実行してみよう．"
      ],
      "metadata": {
        "id": "OA5F9pNW7YNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 1, x, x^2, x^3, ..., x^D をならべたデータ行列（N x (D+1)）をつくる\n",
        "#\n",
        "def makeDataMatrix(x, D):\n",
        "\n",
        "    N = x.shape[0]\n",
        "    X = np.zeros((N, D+1))\n",
        "    X[:, 0] = 1\n",
        "    for d in range(1, D+1):\n",
        "        X[:, d] = x**d\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "UG1n6Z7V7evF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 線形回帰\n",
        "#\n",
        "def LinearRegression(X, y):\n",
        "    # 正規方程式の左辺の行列を A とする\n",
        "    A = X.T @ X\n",
        "    # 正規方程式の右辺のベクトルを b とする\n",
        "    b = X.T @ y\n",
        "    # np.linalg.solve を使って正規方程式を解き，解を w とする\n",
        "    w = np.linalg.solve(A, b)\n",
        "    return w"
      ],
      "metadata": {
        "id": "fc_sd3cs7iBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 実験条件\n",
        "NL, NT = 10, 1000 # 学習データ数，テストデータ数\n",
        "sig = 0.1 # ノイズの標準偏差\n",
        "D = 1 # 多項式次数\n",
        "\n",
        "# 学習データを作って多項式回帰\n",
        "xL, yL = generateData(NL, sigma=sig)\n",
        "XL = makeDataMatrix(xL, D)\n",
        "w = LinearRegression(XL, yL)\n",
        "yL_est = XL @ w\n",
        "msqeL = np.mean((yL - yL_est)**2)\n",
        "\n",
        "# テストデータを作って予測\n",
        "xT, yT = generateData(NT, sigma=sig)\n",
        "XT = makeDataMatrix(xT, D)\n",
        "yT_est = XT @ w\n",
        "msqeT = np.mean((yT - yT_est)**2)\n",
        "\n",
        "## グラフを描く\n",
        "#\n",
        "x_true, y_true = generateData(1000, trueFunc=True)\n",
        "X_true = makeDataMatrix(x_true, D)\n",
        "y_est = X_true @ w\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_xlim(-0.1, 1.1)\n",
        "ax.set_ylim(-0.2, 2.2)\n",
        "ax.plot(x_true, y_true, color='blue', label='true function')\n",
        "ax.scatter(xL, yL, color='red', label='training data')\n",
        "ax.plot(x_true, y_est, color='green', label='fitted curve')\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "# 試行ごとの平均二乗誤差の平均を表示\n",
        "print(f'D = {D}, msqeL = {msqeL:.5f}, msqeT = {msqeT:.5f}')"
      ],
      "metadata": {
        "id": "76Eo4yDL7WM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`msqeL` は，学習データに対する平均二乗誤差(mean squared error)である．モデルを $f(x)$ と表すとき，これは次式で与えられる．\n",
        "\n",
        "$$\n",
        "\\frac{1}{N}\\sum_{n=1}^{N}(y_n - f(x_n))^2\n",
        "$$\n",
        "\n",
        "`msqeT` は，学習データとは別に生成されたテストデータに対する平均二乗誤差である．ここでは，テストデータの生成条件は学習データと同じで，データ数 $N$ のみ異なっている．"
      ],
      "metadata": {
        "id": "cCjgwxk97toa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "観察しよう:\n",
        "- 多項式の次数を変えると `msqeL` はどのように変化するか\n",
        "- 同じく `msqeT` はどのように変化するか"
      ],
      "metadata": {
        "id": "t9YZEySb8cy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行すると，上記の実験をもう少し大規模に行うことができる．ただし，学習データの数を $10$ から $25$ に増やしており，多項式次数 $D$ の値を一つ決めるごとに学習データ（とテストデータ）を1000通り作って1000通りのモデルを学習させている．"
      ],
      "metadata": {
        "id": "aJl3ugF680uY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 実験条件\n",
        "Dlist = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] # 多項式次数\n",
        "Ntrial = 1000 # 試行回数\n",
        "NL, NT = 25, 1000 # 学習データ数，テストデータ数\n",
        "sig = 0.1 # ノイズの標準偏差\n",
        "\n",
        "msqeL = np.zeros((len(Dlist), Ntrial))\n",
        "msqeT = np.zeros((len(Dlist), Ntrial))\n",
        "\n",
        "for i, D in enumerate(Dlist):\n",
        "    for n in range(Ntrial):\n",
        "        xL, yL = generateData(NL, sigma=0.1, seed=2*n)\n",
        "        XL = makeDataMatrix(xL, D)\n",
        "        w = LinearRegression(XL, yL)\n",
        "        yL_est = XL @ w\n",
        "        msqeL[i, n] = np.mean((yL - yL_est)**2)\n",
        "        xT, yT = generateData(NT, sigma=0.1, seed=2*n+1)\n",
        "        XT = makeDataMatrix(xT, D)\n",
        "        yT_est = XT @ w\n",
        "        msqeT[i, n] = np.mean((yT - yT_est)**2)\n",
        "    eL, eT = np.mean(msqeL[i, :]), np.mean(msqeT[i, :])\n",
        "    print(f'# D = {D}, msqeL = {eL:.4g}, msqeT = {eT:.4g}')\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
        "ax[0].boxplot(msqeL.T)\n",
        "ax[0].set_xticklabels(Dlist)\n",
        "ax[0].set_ylim(0, 0.1)\n",
        "ax[0].set_xlabel('D')\n",
        "ax[0].set_title('msqeL')\n",
        "ax[1].boxplot(msqeT.T)\n",
        "ax[1].set_xticklabels(Dlist)\n",
        "ax[1].set_ylim(0, 0.1)\n",
        "ax[1].set_xlabel('D')\n",
        "ax[1].set_title('msqeT')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mTU0TGWK8z3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "グラフの横軸は多項式次数 $D$ を表す．左図の縦軸は，1000回の試行ごとの学習データに対する平均二乗誤差を表し，右図の縦軸は，テストデータに対する同様の値を表す．箱ひげ図なので，箱の中の赤線が1000試行の平均）．"
      ],
      "metadata": {
        "id": "DVNNukv99pT0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "観察しよう:\n",
        "- 多項式の次数を変えると `msqeL` はどのように変化するか\n",
        "- 同じく `msqeT` はどのように変化するか"
      ],
      "metadata": {
        "id": "b-X-1g3w-IIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 汎化と過適合"
      ],
      "metadata": {
        "id": "Nc5xTB7p-KYB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "データが少ないときに次数の大きい多項式を当てはめようとすると，学習データにはよく当てはまっても，その背後にある真の関数関係をうまくとらえられるとは限らず，未知のデータ（テストデータ）に対する当てはまりは逆に大きくなってしまうことがある．このことを，\n",
        "\n",
        "**汎化** できない，**汎化能力** が低い，**過適合** (over-fitting, 過学習)している\n",
        "\n",
        "という．一般に，パラメータ数の多い複雑な学習機械ほど学習データによく当てはまるが，過適合によって未知データにうまく汎化できなくなりがちである．\n",
        "逆に言えば，複雑なモデルでもたくさんのデータを用いて学習させることができるならば，過適合は起こりにくくなる．\n",
        "\n"
      ],
      "metadata": {
        "id": "HR5kUZiK-VjG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下は，上記と同じ問題で，学習データ数を増やしてみた例である．"
      ],
      "metadata": {
        "id": "vGbj8rr6xp4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 実験条件\n",
        "NL, NT = 100, 1000 # 学習データ数，テストデータ数\n",
        "sig = 0.1 # ノイズの標準偏差\n",
        "D = 9 # 多項式次数\n",
        "\n",
        "# 学習データを作って多項式回帰\n",
        "xL, yL = generateData(NL, sigma=sig)\n",
        "XL = makeDataMatrix(xL, D)\n",
        "w = LinearRegression(XL, yL)\n",
        "yL_est = XL @ w\n",
        "msqeL = np.mean((yL - yL_est)**2)\n",
        "\n",
        "# テストデータを作って予測\n",
        "xT, yT = generateData(NT, sigma=sig)\n",
        "XT = makeDataMatrix(xT, D)\n",
        "yT_est = XT @ w\n",
        "msqeT = np.mean((yT - yT_est)**2)\n",
        "\n",
        "## グラフを描く\n",
        "#\n",
        "x_true, y_true = generateData(1000, trueFunc=True)\n",
        "X_true = makeDataMatrix(x_true, D)\n",
        "y_est = X_true @ w\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_xlim(-0.1, 1.1)\n",
        "ax.set_ylim(-0.2, 2.2)\n",
        "ax.plot(x_true, y_true, color='blue', label='true function')\n",
        "ax.scatter(xL, yL, color='red', label='training data')\n",
        "ax.plot(x_true, y_est, color='green', label='fitted curve')\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "# 試行ごとの平均二乗誤差の平均を表示\n",
        "print(f'D = {D}, msqeL = {msqeL:.5f}, msqeT = {msqeT:.5f}')"
      ],
      "metadata": {
        "id": "vV5PhPEsw-Mg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}